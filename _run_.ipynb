{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib        import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "# -------------------------------------------------------------------------------- # sklearn Modules\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import HuberRegressor, LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# -------------------------------------------------------------------------------- # Custom Modules \n",
    "from src import helper\n",
    "from src import cluster\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "RUN_TYPE = \"Colab\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cleanLabels(df, col_name):\n",
    "    avg_gross = helper.mean(df[col_name].to_numpy())\n",
    "    _data = df[col_name].to_numpy()\n",
    "    for index,_ in enumerate(_data):\n",
    "        if _data[index] >= avg_gross:\n",
    "            _data[index] = 3\n",
    "        elif _data[index] >= (avg_gross - avg_gross/2):\n",
    "            _data[index] = 2\n",
    "        elif _data[index] >= avg_gross/2:\n",
    "            _data[index] = 1\n",
    "        else:\n",
    "            _data[index] = 0\n",
    "    df[col_name] = _data\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_df(_DATA_):\n",
    "    _DATA_ = helper.removeNaN(_DATA_, \"gross\")\n",
    "    _DATA_ = helper.removeNaN(_DATA_, \"budget\")\n",
    "    _DATA_ = helper.removeNaN(_DATA_, \"rating\")\n",
    "    _DATA_ = helper.removeNaN(_DATA_, \"score\")   # company\n",
    "\n",
    "    _DATA_ = cleanLabels(_DATA_, \"gross\")\n",
    "    _DATA_ = cleanLabels(_DATA_, \"budget\")\n",
    "\n",
    "\n",
    "\n",
    "    df_rating = [str(i) for i in _DATA_.rating.values]\n",
    "    df_genre   = [str(i) for i in _DATA_.genre.values]\n",
    "    df_company = [str(i) for i in _DATA_[\"company\"].values]\n",
    "\n",
    "\n",
    "    ratingLT = list(set(df_rating))\n",
    "    companyLT = list(set(df_company))\n",
    "    genreLT   = list(set(df_genre))\n",
    "\n",
    "\n",
    "    for idx, row in enumerate(_DATA_.rating):\n",
    "        df_rating[idx] = ratingLT.index(row)\n",
    "\n",
    "    for idx, row in enumerate(_DATA_.genre):\n",
    "        df_genre[idx] = genreLT.index(row)\n",
    "\n",
    "    for idx, row in enumerate(df_company):\n",
    "        df_company[idx] = companyLT.index(row)\n",
    "\n",
    "\n",
    "\n",
    "    _DATA_[\"rating\"] = df_rating\n",
    "    _DATA_[\"genre\"] = df_genre\n",
    "    _DATA_[\"company\"] = df_company\n",
    "    return _DATA_\n",
    "\n",
    "def runClustering(DATA):\n",
    "    for y_col in y_cols:\n",
    "        # print (f\"Generating KNN with\\n   ==> label_col = {y_col}\")\n",
    "        y = DATA[y_col].to_numpy()\n",
    "        X = DATA[X_col].to_numpy()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        KNN = cluster.train(X,y)\n",
    "        crossValResults = cluster.Eval.cross_val(KNN, X_test, y_test)\n",
    "        print(f\"{y_col} -- {helper.mean(crossValResults)}\")\n",
    "        cluster.generateFigure(KNN, X_test, y_test)\n",
    "        return KNN, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-afd79e4bc59a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mDATA_PATH_original\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/movies_original.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# y = df_clean[y_col[0]].to_numpy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-afd79e4bc59a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mDATA_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/movies_v1.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mDATA_ORIGINAL_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/movies_original.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mDATA\u001b[0m               \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mDATA_ORIGINAL\u001b[0m      \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_ORIGINAL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# ------------------------------------------------------------ #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "y_cols = [\"gross\", \"budget\"]\n",
    "X_col = [\"rating\", \"score\", \"genre\",\"company\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    DATA_PATH = \"data/movies_v1.csv\"\n",
    "    DATA_ORIGINAL_PATH = \"data/movies_original.csv\"\n",
    "    DATA               =  pd.read_csv(DATA_PATH)\n",
    "    DATA_ORIGINAL      =  pd.read_csv(DATA_ORIGINAL_PATH)\n",
    "    # ------------------------------------------------------------ #\n",
    "    print(\"Booting up the Movie Recommended System ...\")\n",
    "    print (f\"DATA \")\n",
    "    runClustering(clean_df(DATA))\n",
    "\n",
    "    exit()\n",
    "    print(\"--------------------------------\")\n",
    "    print (f\"DATA -- ORIGINAL\")\n",
    "    # KNN, X_test, y_test = runClustering(clean_df(DATA_ORIGINAL))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    DATA_PATH_original = \"data/movies_original.csv\"\n",
    "    main()\n",
    "\n",
    "    # y = df_clean[y_col[0]].to_numpy()\n",
    "    # X = df_clean[X_col].to_numpy()\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "    # knn = trainCluster(X,y)\n",
    "    # modelEval(knn, X_test, y_test)\n",
    "\n",
    "# print (helper.mean(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
