{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GXE-J604dTW2"},"source":["# Mounting Drive \n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cWcykNXvcXeZ","executionInfo":{"status":"ok","timestamp":1638494381117,"user_tz":360,"elapsed":33643,"user":{"displayName":"Imunique Peculiar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpoxYEqCTF5m9mS1dVVukaqgKzKNhhvo0ScwgH8Q=s64","userId":"17615424903651730669"}},"outputId":"432b4577-ab15-4615-9e63-fc2f271ec099"},"source":["import pandas as pd\n","\n","# if Import PyDrive and associated libraries.\n","# This only needs to be done once per notebook.\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once per notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Search query reference:\n","# https://developers.google.com/drive/v2/web/search-parameters\n","listed = drive.ListFile({'q': \"title contains '.csv'\"}).GetList()\n","for file in listed:\n","  print('title {}, id {}'.format(file['title'], file['id']))\n","\n","\n","link = \"https://drive.google.com/file/d/1ZpS3-3KqUHV1A5-vdwGDoYaN5RlUwWEc/view?usp=sharing\"\n","url = listed[0]['webContentLink']\n","df1 = pd.read_csv(url)\n","\n"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n","    from oauth2client.contrib.locked_file import LockedFile\n","ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n","    from oauth2client.locked_file import LockedFile\n","ModuleNotFoundError: No module named 'oauth2client.locked_file'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n","    from . import file_cache\n","  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n","    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n","ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"]},{"output_type":"stream","name":"stdout","text":["title movies_SORTED.csv, id 1ZpS3-3KqUHV1A5-vdwGDoYaN5RlUwWEc\n"]}]},{"cell_type":"code","metadata":{"id":"miIhXTeT6T08"},"source":["import os\n","import warnings\n","import pandas as pd\n","import statistics\n","import numpy as np\n","import seaborn as sns\n","\n","\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","from sklearn.feature_selection import mutual_info_classif\n","from sklearn.feature_selection import f_regression\n","from sklearn.feature_selection import f_classif\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.preprocessing import PowerTransformer\n","from sklearn.compose import TransformedTargetRegressor\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import HuberRegressor, LinearRegression\n","from sklearn import metrics\n","from sklearn.metrics import confusion_matrix\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","import matplotlib\n","from matplotlib        import pyplot as plt\n","from matplotlib.pyplot import figure\n","\n","\n","plt.style.use('ggplot')\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","def mean(x):\n","  return sum(x)/len(x)\n","\n","def exclui_outliers(df1, col_name):\n","  Q1 = df1[col_name].quantile(.25)\n","  Q3 = df1[col_name].quantile(.75)\n","  IIQ =Q3 -Q1\n","  limite_inf = Q1 -1.5*IIQ\n","  limite_sup = Q3 +1.5*IIQ\n","  return df1[(df1[col_name]>=limite_inf) & (df1[col_name]<=limite_sup)]\n","\n","def removeNaN(df, col_name):\n","  for index, row in enumerate(df[col_name].to_numpy()):\n","      if str(row) == \"nan\":\n","        # print(row)\n","      # if np.isnan(row): \n","        df[col_name][index] = str(float(0))\n","  return df\n","\n","def group_low_freq_cats(df1, col_name, threshold=0.01, name='others'):\n","  df1 = df1.copy()\n","  cat_freq = df1[col_name].value_counts()\n","  cat_low_freq = cat_freq[cat_freq/cat_freq.sum() <= threshold].index\n","  df1.loc[df1[col_name].isin(cat_low_freq),col_name]='others'\n","  return df1\n","\n","def val_couts_cols (df1,cols):\n","  \"\"\" Problems Here\"\"\"\n","\n","  for x in cols:\n","    print('column: {0}, categories: {1}'.format(x,len(df1[x].value_counts())))\n","  print('Total samples: ' + str(len(df1)))\n","\n","  def feature_selection(df1, feature, target ,in_out, method='na'):fs_score =[]\n","  oe = OrdinalEncoder()\n","  X = (np.array(df1[feature])).reshape(-1,1)\n","  oe.fit(X)\n","  X_enc = oe.transform(X)\n","\n","  y = np.array(df1[target]).reshape(-1,1)\n","  oe.fit(y)\n","  y_enc = oe.transform(y)\n","  \n","  if in_out == 'cat_cat': \n","    if method == 'chi2':\n","      fs = SelectKBest(score_func=chi2, k='all') \n","    else:\n","      fs = SelectKBest(score_func=mutual_info_classif, k='all')\n","    fs.fit(X_enc, y_enc)\n","    fs_score = fs.scores_\n","  elif in_out == 'num_num':\n","    fs = SelectKBest(score_func=f_regression, k='all')\n","    fs.fit(X, y.ravel())\n","    fs_score = fs.scores_\n","  elif in_out == 'num_cat':\n","    fs = SelectKBest(score_func=f_classif, k='all')\n","    fs.fit(X, y_enc)\n","    fs_score = fs.scores_\n","  elif in_out == 'cat_num':\n","    fs = SelectKBest(score_func=f_classif, k='all')\n","    fs.fit(X_enc, y.ravel())\n","    fs_score = fs.scores_\n","  else:\n","    fs_score=[]\n","  return fs_score\n","\n","\n","\n","def get_col_type(df1,col_type):\n","  cols_types=df1.dtypes.reset_index()\n","  cols_types.columns=['col','type']\n","  cols_type = cols_types.apply(lambda x: x['col'] if x['type']==col_type else np.nan ,axis=1)\n","  return cols_type.dropna()\n","\n","def boxplot_by_col(df1,cat_cols,target):\n","  fig, ax = plt.subplots(len(cat_cols), 1, figsize=(25, 18))\n","  fig.subplots_adjust()\n","  t=0\n","  for var, subplot in zip(cat_cols, ax.flatten()):\n","      ax[t].set_xlabel(var,fontsize=18)\n","      sort_qtl_index = df1.groupby(var)[target].quantile(0.5).sort_values().index\n","      sort_qtl_values = df1.groupby(var)[target].quantile(0.5).sort_values()\n","      sns.boxplot(x=var, y=target, data=df1, ax=subplot,order=sort_qtl_index)\n","      sns.pointplot(x=sort_qtl_index,y= sort_qtl_values,ax=subplot,color='r')\n","      t+=1    \n","  plt.tight_layout(pad=3) \n","\n","\n","\n","def group_low_freq_cats(df1, col_name, threshold=0.01, name='others'):\n","  df1 = df1.copy()\n","  cat_freq = df1[col_name].value_counts()\n","  cat_low_freq = cat_freq[cat_freq/cat_freq.sum() <= threshold].index\n","  df1.loc[df1[col_name].isin(cat_low_freq),col_name]='others'\n","  return df1\n","\n","\n","def remove_incoherence(DataFrame,expression, replace_val, columns=[]):\n","  \"\"\" Problems Here\"\"\"\n","  \n","  if len(columns)==0:\n","    columns = DataFrame.columns\n","  \n","  DataFrame_aux=DataFrame.copy()\n","  \n","  if str(replace_val) == str(np.nan):\n","    DataFrame_aux=DataFrame.replace(expression, replace_val, regex=True) \n","    return DataFrame_aux\n","  else: \n","    for col in columns:\n","      i=0\n","      while True: \n","        DataFrame_aux[col]=DataFrame[col].str.replace(expression, replace_val, regex=True)\n","        num_matchs = len(DataFrame_aux[DataFrame_aux[col].str.contains(expression, na=False)])\n","        DataFrame = DataFrame_aux\n","        if num_matchs == 0:\n","            break\n","        if i == 100:\n","            DataFrame_aux =pd.DataFrame([])\n","            break\n","        i+=1\n","    return DataFrame_aux"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3jJGBXegE_bt","executionInfo":{"elapsed":5,"status":"ok","timestamp":1638402433420,"user":{"displayName":"S Ebron","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09902615230725488043"},"user_tz":360},"outputId":"6abb54a9-0e17-47e1-e40c-4d43d7380241"},"source":["import numpy as np\n","from sklearn.cluster import KMeans\n","from sklearn.neighbors import NearestNeighbors, NeighborhoodComponentsAnalysis, KNeighborsClassifier\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import cross_val_score\n","\n","def trainCluster(X,y):\n","    \"\"\"KNeighborsClassifier\"\"\"\n","    model = KNeighborsClassifier(n_neighbors=3)\n","    print (len(X), y[0] )\n","    print (len(X), y[0], set(y))\n","    return model.fit(X, y)\n","\n","\n","def modelEval(model, XTests, yTests):\n","    yPreds = model.predict(XTests)\n","    for idx,_ in enumerate(yPreds):\n","      yTest = yTests[idx]\n","      yPred = yPreds[idx]\n","      print(idx, yPred, \"---\",yTest)\n","    results = cross_val_score(model, X, y, cv=5)\n","    print(results)\n","    return \n","\n","\n","\n","\n","\n","def test():\n","  X, y = load_iris(return_X_y=True)\n","  print (X.shape)\n","  print (y.shape)\n","  \n","  # X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.7, random_state=42)\n","  # knn = trainCluster(X,y)\n","  # modelEval(knn, X_test, y_test)\n","\n","  # def runClustering():\n","  #     \"\"\" \"\"\"\n","  #     X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n","  #     knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n","  #     knn.fit(X_train, y_train)\n","  #     y_pred = knn.predict(X_test)\n","  #     sns.scatterplot(\n","  #         x='mean gross',\n","  #         y='mean budget',\n","  #         hue='4500000',\n","  #         data=X_test.join(y_test, how='outer'))\n","  #     cat_cols = get_col_type(df1_fs, 'object')\n","  #     # val_couts_cols(df1_fs,cat_cols)\n","\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["(150, 4)\n","(150,)\n"]}]},{"cell_type":"code","metadata":{"id":"6OLu_1xo2cdu"},"source":["link = \"https://drive.google.com/file/d/1ZpS3-3KqUHV1A5-vdwGDoYaN5RlUwWEc/view?usp=sharing\"\n","url = listed[0]['webContentLink']\n","df1 = pd.read_csv(url)\n","\n","\n","\n","\n","\n","def clean_data(data, n = 5):\n","  y_col = [\"gross\", \"budget\"]\n","  X_col = [\"rating\", \"score\"] # [\"rating\", \"genre\", \"score\", \"company\", \"\"]\n","  df = removeNaN(data, \"rating\")\n","  df = removeNaN(df, \"score\")\n","  df = removeNaN(df, \"gross\")\n","  df = removeNaN(df, \"budget\")\n","\n","  df_ratings = [str(i) for i in df.rating.values]\n","  ratingsLT = list(set(df_ratings))\n","\n","  print(f\"RatingsLT: {ratingsLT}\")\n","  for idx, row in enumerate(df.rating):\n","    df.rating[idx] = ratingsLT.index(row)\n","  return df\n","\n","\n","\n","\n","\n","if __name__ == \"__main__\":\n","    df_clean = clean_data(data = df1)\n","    y = df_clean[y_col[0]].to_numpy()\n","    X = df_clean[X_col].to_numpy()\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)\n","    knn = trainCluster(X,y)\n","    modelEval(knn, X_test, y_test)\n","    \n","    \n","\n","  # X =s \n","\n","  # df1_fs = df1.drop(['country','votes','runtime','released'], axis=1)\n","  # print (f\"df1: {df1_fs}\")\n","  # print (f\"df1 info: {df1_fs.info}\")\n","  # df1_fs = removeNaN(df1_fs, \"budget\")\n","  # df1_fs = removeNaN(df1_fs, \"gross\")\n","  # print ()\n","  # print (df1_fs['gross'])\n","\n","  # print (df1_fs['budget'].plot(kind='box'))\n","  # print (df1_fs['gross'].plot(kind='box'))\n","\n","  # gross_budget = df1_fs[[\"gross\",\"budget\"]]\n","  # gross_mean   = mean(x = df1_fs[\"gross\"])\n","  # budget_mean  = mean(x = df1_fs[\"budget\"])\n","\n","  # print(gross_budget)\n","  # print(gross_mean)\n","  # print(budget_mean)\n","  \n","  # ============================================================ #\n","  # df1.sample(500)\n","  # df1.info()\n","  # df1_fs.info()\n","  # df1_fs.sample(15)\n","  # df1.dropna()\n","  # ============================================================ #\n","  # sns.heatmap(df1_fs.corr(), annot=Tdrue)\n","  # sns.pairplot(df1_fs[['budget','gross','genre']])\n","\n","  # for dirname, _, filenames in os.walk('/kaggle/input'):\n","  #     for filename in filenames:\n","  #         print(os.path.join(dirname, filename))\n","  # warnings.filterwarnings('ignore')\n","  # %matplotlib inline\n","  # matplotlib.rcParams['figure.figsize'] = (12,8)\n","  # pd.options.mode.chained_assignment = None\n","  # df1 = pd.read_csv('https://drive.google.com/uc?id=1ZpS3-3KqUHV1A5-vdwGDoYaN5RlUwWEc&export=download')\n","  # df1.head()\n","\n","\n","  # # print (y)\n","  # # print(df1.target)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zXX7nx9r1_X-","executionInfo":{"elapsed":127,"status":"ok","timestamp":1638402655777,"user":{"displayName":"S Ebron","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09902615230725488043"},"user_tz":360},"outputId":"6db15ee6-b9e8-431f-9ea7-958dc33dd6e8"},"source":["# X = X[[mean_gross, mean_budget]]\n","# y = pd.Categorical.from_codes(df1_gross.target, df1_gross.target_names)\n","# y = pd.get_dummies(y, drop_first=True)\n","\n","print(df1.isnull().sum())\n","print(df1[\"gross\"])\n","\n","df1.dropna(inplace = True)\n","print(df1.isnull().sum())\n","df1['gross'].astype('int64')\n","df1['budget'].astype('int64')\n"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["name        0\n","rating      0\n","genre       0\n","year        0\n","released    0\n","score       0\n","votes       0\n","director    0\n","writer      0\n","star        0\n","country     0\n","budget      0\n","gross       0\n","company     0\n","runtime     0\n","dtype: int64\n","0       758411779.0\n","1       433921300.0\n","2       400063852.0\n","3       359126022.0\n","4       335260290.0\n","           ...     \n","1345    127869379.0\n","1346    161849455.0\n","1349     54323210.0\n","1350     36599361.0\n","1351     52425855.0\n","Name: gross, Length: 1174, dtype: float64\n","name        0\n","rating      0\n","genre       0\n","year        0\n","released    0\n","score       0\n","votes       0\n","director    0\n","writer      0\n","star        0\n","country     0\n","budget      0\n","gross       0\n","company     0\n","runtime     0\n","dtype: int64\n"]},{"data":{"text/plain":["0       180000000\n","1       150000000\n","2       170000000\n","3        40000000\n","4        79000000\n","          ...    \n","1345     50200000\n","1346     27000000\n","1349     13200000\n","1350      8000000\n","1351      4000000\n","Name: budget, Length: 1174, dtype: int64"]},"execution_count":108,"metadata":{},"output_type":"execute_result"}]},{"cell_type":"code","metadata":{"id":"V8JAK1iNEtGR"},"source":["f, (ax1, ax2) = plt.subplots(1, 2, sharey = True)\n","\n","plt.gcf().set_size_inches(15, 7)\n","\n","ax1.boxplot(df1.budget)\n","\n","ax1.set_title('Budget', c = 'green', fontsize = 25)\n","\n","ax2.boxplot(df1.gross)\n","\n","ax2.set_title('Gross', c ='red', fontsize = 25)\n","\n","plt.ylabel('Gross', fontsize = 25)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cm43MrTDKLkq"},"source":["correlation_table = df1.corr(method = 'pearson')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kJHP1Ez9TidR"},"source":["sns.heatmap(correlation_table, annot = True)\n","\n","plt.title('Correlation Heat Map')\n","\n","plt.xlabel('Measuring Features')\n","\n","plt.ylabel('Measuring Features')\n","\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CW7NPAM1Wxc3"},"source":["coded_df1 = df1\n","\n","for col_name in coded_df1.columns:\n","   \n","    if(coded_df1[col_name].dtype == 'object'):\n","      \n","        coded_df1[col_name] = coded_df1[col_name].astype('category')\n","       \n","        coded_df1[col_name] = coded_df1[col_name].cat.codes\n","\n","coded_df1.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LTSMByMWZabM"},"source":["complete_corr_table = coded_df1.corr(method = 'pearson')\n","\n","sns.heatmap(complete_corr_table, annot = True)\n","\n","plt.title('Complete Correlation Heat Map')\n","\n","plt.xlabel('Measuring Features')\n","\n","plt.ylabel('Measuring Features')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZBvcaJiaabCe"},"source":["pairs = complete_corr_table.unstack()\n","sorted_pairs = pairs.sort_values()\n","high_correlation = sorted_pairs[(sorted_pairs) > 0.5]\n","\n","\n","\n","print (pairs)\n","print (sorted_pairs)\n","print (high_correlation)\n","\n","sns.regplot(x='score', y='gross', data=df1, scatter_kws={'color': 'magenta'}, line_kws = {'color': 'blue'})\n","sns.regplot(x='votes', y='gross', data=df1, scatter_kws={'color': 'green'}, line_kws = {'color': 'blue'})\n","sns.regplot(x='budget', y='gross', data=df1, scatter_kws={'color': 'red'}, line_kws = {'color': 'yellow'})\n","sns.stripplot(x=\"rating\", y=\"gross\", data = df1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qbeYcmYPn_sG"},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","from sklearn.feature_selection import mutual_info_classif\n","from sklearn.feature_selection import f_regression\n","from sklearn.feature_selection import f_classif\n","from sklearn.preprocessing import OrdinalEncoder\n","\n","from sklearn.preprocessing import PowerTransformer\n","from sklearn.compose import TransformedTargetRegressor\n","\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.linear_model import HuberRegressor, LinearRegression\n","from sklearn import metrics\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","dataset = pd.read_csv('https://drive.google.com/uc?id=1ZpS3-3KqUHV1A5-vdwGDoYaN5RlUwWEc&export=download',encoding='latin1')\n","dataset.sample(100)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4f-BNCV8dsum"},"source":[""]},{"cell_type":"code","metadata":{"id":"MSL3Na-0sIiI"},"source":["def exclui_outliers(DataFrame, col_name):\n","\n","  Q1 = DataFrame[col_name].quantile(0.25)\n","\n","  Q3 = DataFrame[col_name].quantile(0.75)\n","\n","  IIQ =Q3 -Q1\n","\n","  limite_inf = Q1 -1.5*IIQ\n","\n","  limite_sup = Q3 +1.5*IIQ\n","\n","\n","  return DataFrame[(DataFrame[col_name]>=limite_inf & (DataFrame[col_name]<=limite_sup)]\n","                    \n","def group_low_freq_cats(DataFrame, col_name, threshold=0.01, name='others'):\n","  \n","  df1 = DataFrame.copy()\n","  \n","  cat_freq = df1[col_name].value_counts()\n","  \n","  cat_low_freq = cat_freq[cat_freq/cat_freq.sum() <= threshold].index\n","  \n","  df1.loc[df[col_name].isin(cat_low_freq),col_name]='others'\n","  \n","  return df1\n","\n","\n","def val_couts_cols (Dataframe,cols):\n","  for x in cols:\n","    print('column: {0}, categories: {1}'.format(x,len(Dataframe[x].value_counts())))\n","  print('Total samples: ' + str(len(Dataframe)))\n","\n","#dataset_fs = exclui_outliers(dataset_fs, 'budget', 'gross')\n","#dataset_fs['budget'].plot(kind='box') & dataset_fs['gross'].plot(kind='box')\n","\n","\n","dataset_fs = dataset.drop(['name','country','score', 'votes'],axis=1)\n","dataset_fs['released'] = pd.to_datetime(dataset_fs['released'])\n","dataset_fs['released']=(dataset_fs['released'].dt.month).astype('object')\n","dataset_fs[dataset_fs['gross']==0.0]= np.nan # Problem Here \n","dataset_fs=dataset_fs.dropna()\n","dataset_fs.sample(15)\n","\n","\n","print (dataset.info())\n","print (dataset_fs.info())\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LofXF4jQ24xu"},"source":["plt.figure(figsize=(13,9))\n","sns.heatmap(dataset_fs.corr(),annot=True)\n","sns.pairplot(dataset_fs[['gross','runtime','year','budget']])\n","\n","dataset_fs['budget'].plot(kind='box')\n","dataset_fs['gross'].plot(kind='box')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iBbUQoJdBW16"},"source":["def feature_selection(Dataset, feature, target ,in_out, method='na'): \n","  \n","  fs_score =[]\n","  \n","  oe = OrdinalEncoder()\n","\n","  \n","  X = (np.array(Dataset[feature])).reshape(-1,1)\n","  \n","  oe.fit(X)\n","  \n","  X_enc = oe.transform(X)\n","\n","  \n","  y = np.array(Dataset[target]).reshape(-1,1)\n","  \n","  oe.fit(y)\n","  \n","  y_enc = oe.transform(y)\n","  \n","  \n","  if in_out == 'cat_cat': \n","  \n","    if method == 'chi2':\n","  \n","      fs = SelectKBest(score_func=chi2, k='all') \n","  \n","    else:\n","  \n","      fs = SelectKBest(score_func=mutual_info_classif, k='all')\n","  \n","    fs.fit(X_enc, y_enc)\n","  \n","    fs_score = fs.scores_\n","  \n","  elif in_out == 'num_num':\n","  \n","    fs = SelectKBest(score_func=f_regression, k='all')\n","  \n","    fs.fit(X, y.ravel())\n","  \n","    fs_score = fs.scores_\n","  \n","  elif in_out == 'num_cat':\n","  \n","    fs = SelectKBest(score_func=f_classif, k='all')\n","  \n","    fs.fit(X, y_enc)\n","  \n","    fs_score = fs.scores_\n","  \n","  elif in_out == 'cat_num':\n","  \n","    fs = SelectKBest(score_func=f_classif, k='all')\n","  \n","    fs.fit(X_enc, y.ravel())\n","  \n","    fs_score = fs.scores_\n","  \n","  else:\n","  \n","    fs_score=[]\n","\n","  \n","  return fs_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BA_hbDp_B5IC"},"source":["def get_col_type(df1,col_type):\n","  \n","  cols_types=df1.dtypes.reset_index()\n","  \n","  cols_types.columns=['col','type']\n","  \n","  cols_type = cols_types.apply(lambda x: x['col'] if x['type']==col_type else np.nan ,axis=1)\n","  \n","  return cols_type.dropna()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o0ieqFbNCOhM"},"source":["def boxplot_by_col(df1,cat_cols,target):\n","  \n","  fig, ax = plt.subplots(len(cat_cols), 1, figsize=(25, 18))\n","  \n","  fig.subplots_adjust()\n","  \n","  t=0\n","  \n","  for var, subplot in zip(cat_cols, ax.flatten()):\n","  \n","      ax[t].set_xlabel(var,fontsize=18)\n","  \n","      sort_qtl_index = df.groupby(var)[target].quantile(0.5).sort_values().index\n","  \n","      sort_qtl_values = df.groupby(var)[target].quantile(0.5).sort_values()\n","  \n","      sns.boxplot(x=var, y=target, data=df, ax=subplot,order=sort_qtl_index)\n","  \n","      sns.pointplot(x=sort_qtl_index,y= sort_qtl_values,ax=subplot,color='b')\n","  \n","      t+=1    \n","  \n","  plt.tight_layout(pad=3) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Bq9zXX6CmrH"},"source":["def remove_incoherence(DataFrame,expression, replace_val, columns=[]):\n","  \n","  if len(columns)==0:\n","    \n","    columns = DataFrame.columns\n","  \n","  DataFrame_aux=DataFrame.copy()\n","  \n","  if str(replace_val) == str(np.nan):\n","    \n","    DataFrame_aux=DataFrame.replace(expression, replace_val, regex=True) # do not use str.replace because it doesn't accept np.nan\n","    \n","    return DataFrame_aux\n","  \n","  else: \n","  \n","    for col in columns:\n","      i=0\n","  \n","      while (True): # when working with groups in the regex, it is not able to replace all groups, so it is necessary to iterate with each new replacement.\n","        \n","        DataFrame_aux[col]=DataFrame[col].str.replace(expression, replace_val, regex=True)\n","\n","        #warnings.filterwarnings('ignore','UserWarning') # avoid warning when str.contains calls expressions containing groups that will not be used\n","        \n","        num_matchs = len(DataFrame_aux[DataFrame_aux[col].str.contains(expression, na=False)])#  check if the regex worked, if so it returns 0, otherwise it returns the number of matches\n","        \n","        DataFrame = DateFrame_aux\n","       \n","        \n","        if num_matchs == 0:\n","           \n","            break\n","        \n","        if i == 100:\n","        \n","            DataFrame_aux =pd.DataFrame([])\n","        \n","            break\n","        \n","        i+=1\n","    \n","    return DataFrame_aux"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aR4H4h6tFMpz"},"source":["cat_cols = get_col_type(dataset_fs, 'object')\n","val_couts_cols(dataset_fs,cat_cols)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l8aU8fF1dHma"},"source":["# Sheldon is Here!!!!\n","import pandas as pd\n","\n","def clean_dataset(df1):\n","  assert isinstance(df1, pd.DataFrame), \"df1 needs to be a pd.DataFrame\"\n","  df1.dropna(inplace=True)\n","  indices_to_keep = ~df1.isin([np.nan, np.inf, -np.inf]).any(1)\n","  return df1[indices_to_keep].astype(np.float64)\n","\n","\n","fs_scores = [ ]\n","for x in cat_cols:\n","    fs_scores - feature_selection(dataset_fs, x, 'budget', 'cat_num')\n","    print('column: {0}, fs_scores: {1}'.format(x, fs_scores))\n","    fs_scores.append(fs_scores)\n","    \n","np.mean(fs_scores)"],"execution_count":null,"outputs":[]}]}